{
  "hash": "00b88135586e3f142d1c1d572db05cdd",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Cardiovascular Dynamics: 12-to-8 Interval Analysis\"\nauthor: \"Olgert Denas\"\ndate: \"2026-01-03\"\ncategories: [b-splines, data-wrangle, ai-conversations]\ndraft: false\nformat:\n    html:\n        toc: true\n        code-fold: true\n        self-contained: true\nexecute: \n  warning: false\n  echo: true\n---\n\n::: {#fd7ea79e .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport arviz as az\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import FancyArrowPatch\nfrom sklearn.preprocessing import SplineTransformer\nfrom scipy.integrate import trapezoid\nfrom dataclasses import dataclass, field, InitVar\nfrom typing import List, Optional, Tuple\nfrom pathlib import Path\nimport seaborn as sns\nfrom dataclasses import dataclass, field\nimport matplotlib.cm as cm\nfrom scipy.signal import medfilt\n\n@dataclass(frozen=True)\nclass WorkoutPhase:\n    name: str\n    duration_sec: int\n    intensity: str  # 'low', 'high', or 'cooldown'\n\n@dataclass(frozen=True)\nclass WorkoutConfig:\n    phases: List[WorkoutPhase]\n    \n    @property\n    def total_duration(self) -> int:\n        return sum(p.duration_sec for p in self.phases)\n\n\n    def iter_phases(self):\n        current_time = 0\n        for phase in self.phases:\n            yield phase, (current_time, current_time + phase.duration_sec)\n            current_time += phase.duration_sec\n\n\n    def get_windows(self, intensity: str) -> List[Tuple[int, int]]:\n        \"\"\"Calculates (start, end) timestamps for all intervals of given intensity.\"\"\"\n        windows = []\n        current_time = 0\n        for phase in self.phases:\n            if phase.intensity == intensity:\n                windows.append((current_time, current_time + phase.duration_sec))\n            current_time += phase.duration_sec\n        return windows\n\n    def get_cooldown_window(self) -> Tuple[int, int]:\n        for phase, (s, e) in self.iter_phases():\n            if phase.intensity == 'cooldown':\n                return s, e\n        raise ValueError(\"No cooldown phase defined in config.\")\n\ndef read_csv(file):        \n    df = pd.read_csv(file, skiprows=2).iloc[:, 1:3]\n    if '2025-12-24' in file.stem:\n        pad_df = df.head(110)\n        df = pd.concat([pad_df, df])\n    td = pd.to_timedelta(df['Time'])\n    df['Time_sec'] = td.dt.total_seconds()\n    return df\n\n\n\ndef load_preprocess_and_filter(file_paths, kernel_size=11, n_drop=0):\n    \"\"\"\n    1. Loads CSVs and drops the first N data points.\n    2. Resets time so the first remaining point is t=0.\n    3. Interpolates to a common grid and applies a Median Filter.\n    \"\"\"\n    processed_dfs = []\n    max_duration = 0\n    \n    # Pass 1: Load, Drop, and find global max time\n    for file in file_paths:\n        df = read_csv(file)\n        \n        # --- Constraint: Drop first N points ---\n        if n_drop > 0:\n            df = df.iloc[n_drop:].reset_index(drop=True)\n            \n        # Convert Time to seconds\n        df['Time_sec'] = pd.to_timedelta(df['Time']).dt.total_seconds()\n        \n        # Shift Time_sec so that the first point after dropping is t=0\n        # This ensures all sessions align at the same relative start point\n        df['Time_sec'] = df['Time_sec'] - df['Time_sec'].iloc[0]\n        \n        if df['Time_sec'].max() > max_duration:\n            max_duration = df['Time_sec'].max()\n            \n        processed_dfs.append(df)\n    \n    common_time = np.arange(0, int(max_duration) + 1, 1)\n    data_list = []\n    \n    for df in processed_dfs:\n        # Interpolate HR onto the common grid\n        hr_interp = np.interp(common_time, df['Time_sec'], df['HR (bpm)'])\n        \n        # Apply Median Filtering to handle Type 1 errors (substantial jitters)\n        hr_cleaned = medfilt(hr_interp, kernel_size=kernel_size)\n        \n        data_list.append(hr_cleaned)\n        \n    return common_time, np.array(data_list)\n\n\n\n@dataclass(frozen=True)\nclass MedianHdi:\n    median: float\n    hdi: Tuple[float, float]\n\n\n    @classmethod\n    def from_samples(cls, samples, hdi_prob=0.89):\n        return cls(np.median(samples, axis=0), tuple(az.hdi(samples, hdi_prob=hdi_prob)))\n\n    @property\n    def hdi_width(self):\n        return self.hdi[1] - self.hdi[0]\n    @property\n    def hdi_lower(self):\n        return self.hdi[0]\n    @property\n    def hdi_upper(self):\n        return self.hdi[1]\n\n@dataclass(frozen=True)\nclass MedianHdiSample:\n    median: np.ndarray\n    hdi: np.ndarray\n\n    @classmethod\n    def from_samples(cls, samples, n_samples, hdi_prob=0.89):\n        assert samples.shape[0] == n_samples\n        return cls(np.median(samples, axis=0), az.hdi(samples, hdi_prob=hdi_prob))\n\n    @property\n    def hdi_width(self):\n        return self.hdi[:, 1] - self.hdi[:, 0]\n    @property\n    def hdi_lower(self):\n        return self.hdi[:, 0]\n    @property\n    def hdi_upper(self):\n        return self.hdi[:, 1]\n\n\ndef fit_bayesian_spline(time, hr_data, total_duration, degree, sample_size, knot_every):\n    \"\"\"\n    Factored model definition. \n    Returns the basis matrix (B), its derivative (dB_dt), and the MAP weights.\n    \"\"\"\n    # 1. Create Basis\n    knots = np.array(range(0, total_duration+1, knot_every)).reshape((-1, 1))\n    transformer = SplineTransformer(knots=knots, degree=degree, include_bias=True)\n    B = transformer.fit_transform(time.reshape(-1, 1))\n    \n    # 2. Compute Derivative Basis\n    # We use gradient here to get the slope of the basis functions\n    dB_dt = np.gradient(B, axis=0)\n\n    # 3. Bayesian Model Definition\n    with pm.Model() as model:\n        w = pm.Normal(\"w\", mu=130, sigma=40, shape=B.shape[1])\n        mu = pm.Deterministic(\"mu\", pm.math.dot(B, w))\n        # Derivative/Punch at every time step\n        accel = pm.Deterministic(\"accel\", pm.math.dot(w, dB_dt.T))\n        \n        sigma = pm.HalfNormal(\"sigma\", sigma=5)\n        if hr_data is None:\n            pm.Normal(\"obs\", mu=mu, sigma=sigma)\n        else:\n            pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=hr_data)\n        \n        # Sampling 1000 draws to build the HDI\n        chains = 2\n        trace = pm.sample(int(sample_size / chains), tune=1000, chains=chains, target_accept=0.9, progressbar=False)\n        \n    return trace, B\n\n\n\n\n\ndef apply_workout_grid(ax, config: WorkoutConfig):\n    \"\"\"\n    Overlays the workout structure onto a heart rate plot.\n    Shades 'high' intensity regions and labels each phase.\n    \"\"\"\n\n    y_min, y_max = ax.get_ylim()\n\n    xticks = []    \n    for phase, (start, end) in config.iter_phases():\n        if phase.intensity == 'low' or phase.intensity == 'cooldown': \n            xticks.append(start)\n        # 1. Shade the High Intensity windows\n        if phase.intensity == 'high':\n            ax.axvspan(start, end, color='red', alpha=0.05, label='_nolegend_')\n            \n        # 2. Draw vertical transition lines\n        ax.axvline(start, color='grey', linestyle='--', alpha=0.3, linewidth=1)\n        \n        # 3. Add Phase Labels at the top of the plot\n        midpoint = start + (phase.duration_sec / 2)\n        # Only label if the phase is long enough to avoid clutter\n        if phase.duration_sec >= 60:\n            ax.text(midpoint, y_max * 0.98, phase.name, \n                    fontsize=8, ha='center', color='grey', alpha=0.7)\n    # Mark the final boundary\n    ax.axvline(config.total_duration, color='grey', linestyle='--', alpha=0.3, linewidth=1)\n    ax.set_xticks(xticks + [config.total_duration])\n\n\n\n@dataclass\nclass TreadmillAnalytic:\n    time: np.ndarray\n    hr: Optional[np.ndarray]\n    session_id: str\n    degree: int\n    config: WorkoutConfig\n\n    # Storage for processed curves\n    n_intervals: int =  field(init=False, repr=False)\n    trace: az.InferenceData = field(init=False, repr=False)\n    post_mu: np.ndarray = field(init=False, repr=False)  # samples x seconds\n    post_accel: np.ndarray = field(init=False, repr=False)\n    load_cache: InitVar[bool] = False\n    cache_path: InitVar[Path | None] = None\n\n    def __post_init__(self, load_cache, cache_path):\n        \"\"\"Coordinates the model fitting and signal generation.\"\"\"\n\n        self.n_intervals = len(self.config.get_windows(\"high\"))\n        n_samples = 1000\n        if load_cache and cache_path is not None and cache_path.exists():\n            self.trace = az.from_netcdf(cache_path)\n        else:\n            self.trace, _ = fit_bayesian_spline(self.time, self.hr, self.config.total_duration, self.degree, n_samples, 30)\n            self.trace.to_netcdf(cache_path)\n        \n        # Extract posteriors\n        self.post_mu = az.extract(self.trace, var_names=\"mu\").values.T\n        self.post_accel = az.extract(self.trace, var_names=\"accel\").values.T\n        \n        assert self.post_mu.shape == (n_samples, self.time.shape[0])\n        assert self.post_accel.shape == (n_samples, self.time.shape[0])\n\n    def get_acceleration_peaks(self) -> List[Tuple[WorkoutPhase, MedianHdi]]:\n        results = []\n        for phase, (phase_start, phase_end) in self.config.iter_phases():\n            win = (self.time >= phase_start) & (self.time <= phase_end)\n            # Get the max for EVERY sample in the window (Result: 2000 max values)\n            if phase.intensity == \"high\":\n                sample_peaks = self.post_accel[:, win].max(axis=1)\n            elif phase.intensity == \"low\" or phase.intensity == \"cooldown\":\n                sample_peaks = self.post_accel[:, win].min(axis=1)\n            else:\n                raise ValueError(f\"Unknown intensity: {phase.intensity}\")\n            results.append((phase, MedianHdi.from_samples(sample_peaks)))\n        return results\n\n    def get_hrr60(self) -> Tuple[WorkoutPhase, MedianHdi]:\n        for phase, (phase_start, phase_end) in self.config.iter_phases():\n            if phase.name != \"Cd\":\n                continue\n            delta_dist = 60 * (self.post_mu[:, phase_start] - self.post_mu[:, phase_end]) / phase.duration_sec\n            return (phase, MedianHdi.from_samples(delta_dist))\n        raise ValueError(\"No cooldown phase defined in config.\")\n\n    def get_cardiac_costs(self) -> List[Tuple[WorkoutPhase, MedianHdi]]:\n        costs = []\n        # Get the window for each phase\n        for phase, (phase_start, phase_end) in self.config.iter_phases():\n            win = (self.time >= phase_start) & (self.time <= phase_end)\n            # 2. Calculate the cost for every single sample (HR is in BPM, so we divide by 60)\n            # This gives you a distribution of 2000 'Total Beats' values\n            cardiac_costs_dist = np.trapezoid(self.post_mu[:, win], self.time[win], axis=1) / 60\n            costs.append((phase, MedianHdi.from_samples(cardiac_costs_dist)))\n        return costs\n\n    @staticmethod\n    def results_to_df(results: List[Tuple[WorkoutPhase, MedianHdi]]) -> pd.DataFrame:\n        return pd.DataFrame([(phase.name, metric.median, metric.hdi_lower, metric.hdi_upper) for phase, metric in results],\n                             columns=[\"Interval\", \"mean\", \"low\", \"high\"])\n\n\n@dataclass\nclass TreadmillReport:\n    workout_structure: WorkoutConfig\n\n    # time_axis: np.ndarray = field(init=False)\n    sessions: List[TreadmillAnalytic] = field(init=False)\n    accel_results: List[Tuple[WorkoutPhase, MedianHdi]] = field(init=False)\n    hrr60_results: List[Tuple[WorkoutPhase, MedianHdi]] = field(init=False)\n    cardiac_cost_results: List[Tuple[WorkoutPhase, MedianHdi]] = field(init=False)\n    data_directory: InitVar[List[Path]]\n    with_prior: bool\n\n    def __post_init__(self, file_paths: List[Path]):\n        degree = 3\n        session_names = [p.stem[6:16] for p in file_paths]\n        cache_paths = [file_path.with_suffix(\".nc\") for file_path in file_paths]\n        time_axis, raw_data_matrix = load_preprocess_and_filter(file_paths, kernel_size=1, n_drop=240)\n\n        self.sessions = [\n            TreadmillAnalytic(time_axis, hr_data, sn, degree, self.workout_structure, True, cp) \n            for hr_data, sn, cp in zip(raw_data_matrix, session_names, cache_paths)\n        ]\n        if self.with_prior:\n            self.sessions.append(\n                TreadmillAnalytic(time_axis, None, \"2026-02-01_00-00-00\", degree, self.workout_structure, True, Path(\"prior.nc\"))\n            )\n        assert len(file_paths) == len(session_names)\n        assert len(file_paths) == raw_data_matrix.shape[0]\n        np.any(np.isnan(raw_data_matrix))\n\n    def plot_raw_data(self):\n        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n        for session in self.sessions:\n            if session.hr is None:\n                continue\n            ax.plot(session.time, session.hr, color='gray', linewidth=1, label=session.session_id)\n\n        ax.set_title(\"Heart Rate Data (%d Sessions)\" % len(self.sessions))\n        ax.set_ylabel(\"HR (bpm)\")\n        ax.set_xlabel(\"Time (seconds)\")\n        apply_workout_grid(ax, self.workout_structure)    \n        \n\n    def plot_fit_accel(self, fig, axes):\n        n_sessions = len(axes[1])\n        for i, session in enumerate(self.sessions[-n_sessions:]):\n            ax1, ax2 = axes[0, i], axes[1, i]\n            hr_stats = MedianHdiSample.from_samples(session.post_mu, session.post_mu.shape[0])\n            acc_stats = MedianHdiSample.from_samples(session.post_accel, session.post_accel.shape[0])\n\n            # --- Top Plot: Heart Rate ---\n            if session.hr is not None:\n                ax1.scatter(session.time, session.hr, color='black', s=1, alpha=0.2)\n            ax1.plot(session.time, hr_stats.median, color='firebrick', linewidth=2.5, label='Posterior Median HR')\n            ax1.fill_between(session.time, hr_stats.hdi_lower, hr_stats.hdi_upper, color='firebrick', alpha=0.2)\n            ax1.set_ylabel(\"Heart Rate (bpm)\")\n            ax1.set_title(session.session_id)\n            apply_workout_grid(ax1, self.workout_structure)\n\n            # --- Bottom Plot: Acceleration ---\n            ax2.plot(session.time, acc_stats.median, color='indigo', linewidth=2, label='HR Acceleration')\n            ax2.axhline(0, color='black', linewidth=1, alpha=0.5)\n            ax2.fill_between(session.time, acc_stats.hdi_lower, acc_stats.hdi_upper, color='firebrick', alpha=0.2)\n            ax2.set_ylabel(\"Acceleration ($\\\\Delta$BPM/sec)\", fontweight='bold')\n            ax2.set_xlabel(\"Time (seconds)\", fontweight='bold')\n            apply_workout_grid(ax2, self.workout_structure)\n\n    \n    def plot_trend_vector(self, fig, ax, code):\n        \"\"\"Plots historical sessions with a vector arrow and session name annotations.\"\"\"\n\n        all_coords = []\n        for s in self.sessions:\n            punches = [punch for (phase, punch) in s.get_acceleration_peaks() if phase.intensity == 'high']\n            hrr60 = s.get_hrr60()[1]\n            x_stat = punches[0]\n            y_stat = (hrr60 if code == 'ph' else punches[-1])\n            all_coords.append((x_stat.median, y_stat.median, \n                               (x_stat.median - x_stat.hdi_lower, x_stat.hdi_upper - x_stat.median), \n                               (y_stat.median - y_stat.hdi_lower, y_stat.hdi_upper - y_stat.median)))\n\n        for i, (session, (x_mu, y_mu, x_err, y_err)) in enumerate(zip(self.sessions, all_coords)):\n            ax.errorbar(x_mu, y_mu, xerr=[x_err[0]], yerr=[y_err[0]],\n                        fmt='o', color='teal', alpha=0.5, capsize=0, elinewidth=1.2, markersize=4)\n            ax.annotate(session.session_id, xy=(x_mu, y_mu), \n                        xytext=(5, 5), textcoords='offset points', fontsize=5, color='#333333')\n            \n            if i > 0:\n                prev_x, prev_y, _, _ = all_coords[i-1]\n                arrow = FancyArrowPatch((prev_x, prev_y), (x_mu, y_mu),\n                                        arrowstyle='-|>', mutation_scale=15, color='teal',\n                                        linestyle='-', linewidth=1.5, alpha=0.3, shrinkA=5, shrinkB=5)\n                ax.add_patch(arrow)\n\n        # Formatting\n        fig.suptitle(\"Longitudinal Fitness Evolution\")\n        ax.set_xlabel(\"1st Punch (Max Accel - BPM/s)\")\n        if code == 'ph': \n            ax.set_ylabel(\"Recovery (HRR60 - BPM)\")\n        else:\n            ax.set_ylabel(\"Last Punch (Max Accel - BPM/s)\")\n        ax.grid(True, linestyle=':', alpha=0.4)\n        \n\n    def plot_cardiac_cost(self):\n        cc_df = pd.concat([TreadmillAnalytic.results_to_df(s.get_cardiac_costs())\n                            .assign(session=s.session_id)\n                            .assign(session_date=lambda x: pd.to_datetime(x.session.str[:10]))\n                            for s in self.sessions]).reset_index().rename(columns={'mean': 'cc'})\n        ax = sns.pointplot(x='session_date', y='cc', hue='Interval', data=cc_df, legend='brief')\n        ax.set_ylabel(\"Cardiac Cost (Total Beats)\")\n        sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n\n\n# Your current specific workout: 3 reps of (3m low, 1m high) + 2m cooldown\nstandard_3x4 = WorkoutConfig(phases=[\n    WorkoutPhase(f\"R1\", 180, 'low'), WorkoutPhase(f\"S1\", 60, 'high'),\n    WorkoutPhase(f\"R2\", 180, 'low'), WorkoutPhase(f\"S2\", 60, 'high'),\n    WorkoutPhase(f\"R3\", 180, 'low'), WorkoutPhase(f\"S3\", 60, 'high'),\n    WorkoutPhase(\"Cd\", 120, 'cooldown')\n])\n\n_cdw = standard_3x4.get_cooldown_window()\n\nfile_paths = list(sorted(Path(\"polar_data\").glob(\"*.CSV\")))\nreport = TreadmillReport(standard_3x4, file_paths, True)\nign_session = report.sessions[-1]\nex_session = report.sessions[-2]\nex_time_point = 310\n```\n:::\n\n\nIf you use a heart rate monitor to monitor your exercise, it is important to wear it a few minutes after the exercise. In those minutes your body recovers and your heart rate drops until it reaches it's normal rate. The faster the heart does that the better – a drop of $\\geq 25$ BPMs each minute is good, the higher the better.\n\nThere are other things one can measure during the exercise. For an interval training run, where you alternate between a 1 minute 8min/mile sprint (`S`) and a light 3 minute 12min/mile recovery (`R`) run, one can measure:\n\n-   how fast the heart reaches it's high rate as you start to sprint, or the punch – the faster the better\n\n-   whether the first punch is as high as the last punch – if so, your endurance is good.\n\n-   how fast it beats during a sprint – if it can get away with a smaller rate, it means it is more efficient\n\nThe problem is, hear rate monitors are not perfect. My polar band (a strap around the chest), is noisy so measuring these values is hard on the raw data. But one can fit a curve, and measure these values on the curve. Which exactly what we'll do here!\n\nHere are the data for 5 exercise sessions. I start monitoring as soon as I start running, the 2 minutes of cool down start at second 720.\n\n::: {#00a2229f .cell execution_count=2}\n``` {.python .cell-code}\nreport.plot_raw_data()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\nBelow are the median heart rate and acceleration from the fitted (generative) models over the last few exercise sessions. The rightmost model is the prior.\n\n::: {#ffe099cd .cell execution_count=3}\n``` {.python .cell-code}\nfig, axes = plt.subplots(ncols=len(report.sessions[-3:]), nrows=2, figsize=(14, 6), sharex=True, sharey='row')\nreport.plot_fit_accel(fig, axes)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\nAt each second the model provides a (posterior) distribution for the heart rate or its acceleration. For example, this is the distribution of the heart rate for the exercise session 2026\\-01\\-05 at two time points.\n\n::: {#fa59722c .cell execution_count=4}\n``` {.python .cell-code}\nex_session = report.sessions[0]\nex_time_spot1 = 120\nex_time_spot2 = 230\nsamples = ex_session.post_mu.shape[0]\nsns.displot(data=pd.DataFrame(\n    {\n        'heart_rate': np.concatenate([ex_session.post_mu[:,ex_time_spot1], ex_session.post_mu[:,ex_time_spot2]]),\n        'time_spot': ([f\"second {ex_time_spot1}\"] * samples) + ([f\"second {ex_time_spot2}\"] * samples)\n    }\n\n    ), x='heart_rate', hue='time_spot', kind='kde'\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nBelow is my fitness evolution:\n\n-   left plot is the first punch vs. HRR – I want the path to go north-east\n\n-   right plot is the first vs. last punch – I want the path to match the `x=y` line\n\n::: {#2580c00f .cell execution_count=5}\n``` {.python .cell-code}\nreport = TreadmillReport(standard_3x4, file_paths, False)\nfig, ax_quad = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=False)\nreport.plot_trend_vector(fig, ax_quad[0], 'ph')\nreport.plot_trend_vector(fig, ax_quad[1], 'pp')\nax_quad[1].axline((0, 0), slope=1, color='r', linestyle='--', label='$x=y$ line'); ax_quad[1].legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\nBelow is also the total cardiac cost (total heart beats per interval). Recovery intervals are higher because they are longer. I want these lines to trend down.\n\n::: {#c40dc90a .cell execution_count=6}\n``` {.python .cell-code}\nreport.plot_cardiac_cost()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\n##\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}